---
title: 日志处理的整体流程
date: 2025-08-31 10:30:05
tags: 日志处理
---

# 🔎 ELK 日志处理的整体流程


1. **日志产生**

- 各种应用（比如你的基础平台服务、流程审批服务）、中间件（Kafka、MySQL、Nacos 等）不断产生日志文件或标准输出。
2. **日志采集（Logstash / Beats）**

- **Filebeat / Logstash** 读取日志文件或接受日志流。
- 可以在这里做 **过滤、格式化、解析 JSON** 等预处理。
3. **日志传输到 Elasticsearch**
<!--more-->
- 处理好的日志被发送到 **Elasticsearch**，按照 **索引 (Index)** 存储。
- Elasticsearch 会自动为日志建立 **倒排索引**，方便后续全文检索。
4. **日志存储与索引**

- Elasticsearch 按时间、业务、服务维度切分日志索引。
- 日志被分布式存储在多个节点上。
5. **日志可视化与分析（Kibana）**

- **Kibana** 提供 Web 界面，连接 Elasticsearch。
- 用户可以：


检索关键字日志


画出趋势图（比如错误量随时间的变化）


构建仪表盘（Dashboard）


# ⚙️ 具体操作流程（举例）


以 **流程审批服务** 的日志为例，走一遍：


1. **应用写日志**

- 你的审批服务在 `/var/log/approval-service.log` 里记录：

```vbnet
2025-08-30 10:10:05 ERROR OrderApprovalService - 审批流程失败，原因：数据库超时

```
2. **Logstash / Filebeat 采集**

- Filebeat/Logstash 读取日志：


**Input 插件**：指定读取文件路径。


**Filter 插件**：用 Grok 正则解析日志格式，提取出时间戳、级别、模块、消息。


转换成结构化 JSON：

```json
{
  "timestamp": "2025-08-30T10:10:05",
  "level": "ERROR",
  "service": "OrderApprovalService",
  "message": "审批流程失败，原因：数据库超时"
}

```
3. **发送到 Elasticsearch**

- Logstash 用 **Output 插件** 把日志写入 Elasticsearch，存储到索引：


index: `approval-service-2025.08.30`
4. **Elasticsearch 存储与索引**

- Elasticsearch 将日志存储在分片中，并建立索引。
- 支持按 `level:ERROR` 或 `service:OrderApprovalService` 进行搜索。
5. **Kibana 可视化**

- 在 Kibana 仪表盘里：


搜索 `level:ERROR` → 可以看到所有错误日志。


画一个图表：过去 24 小时审批失败次数的趋势。


如果接入告警系统，还能在错误数量超过阈值时通知运维。


# 📊 ELK 在你项目里的价值


- **基础平台服务**


监控各个中间件（Kafka、MySQL、Redis 等）的运行日志。


快速定位中间件故障。
- **流程审批服务**


记录审批操作日志、异常信息。


管理员可以通过 Kibana 查询“某用户审批历史”，或“最近 7 天失败的审批流程”。


# ✅ 总结


ELK 的日志处理流程可以概括为：
**日志采集 → 格式化 → 存储索引 → 搜索分析 → 可视化 & 告警**。


- **Logstash/Beats**：采集 & 格式化日志
- **Elasticsearch**：存储 & 检索日志
- **Kibana**：展示 & 可视化